import os
import numpy as np
from PIL import Image
import gradio as gr
from dotenv import load_dotenv
import tempfile

def generate_prompt(image_path):
    prompt_obj = get_prompt(image_path, openai_api_key, openai_base_url)
    return prompt_obj.message.content if hasattr(prompt_obj, "message") else prompt_obj

def run_sampler(input_image, prompt, cfg_scale=9, image_strength=0.7):
    img = Image.fromarray(np.array(input_image)).convert('RGB')
    img = np.array(process(np.array(img), flip=True))

    a_prompt = "solo, cute, beautiful face, high quality, detailed, best quality, masterpiece, beautiful eyes"
    n_prompt = "blurry, low quality, twisted, ugly, deformed, distorted, bad anatomy, bad face, text, error, missing fingers, extra digit, fewer digits"
    print(prompt)
    result = sampler.process(
        img, prompt, a_prompt, n_prompt,
        1, 512, 50, False, image_strength, cfg_scale, -1, 0.0
    )
    
    return Image.fromarray(result)


def run_adain(content_img, style_img, alpha=0.7):
    import uuid
    import shutil

    current_dir = os.getcwd()
    os.chdir("pytorch-AdaIN")

    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
    content_path = f"content_{uuid.uuid4().hex}.png"
    style_path = f"style_{uuid.uuid4().hex}.png"
    content_img.save(content_path)
    style_img.save(style_path)

    cmd = (
        f"python test.py --content {content_path} --style {style_path}"
        f" --alpha {alpha} --content_size 512 --style_size 512 --output . --save_ext .png"
    )
    os.system(cmd)

    stylized_name = f"{os.path.splitext(content_path)[0]}_stylized_{os.path.splitext(style_path)[0]}.png"
    result = None
    if os.path.exists(stylized_name):
        result = Image.open(stylized_name).convert('RGB')
        os.remove(stylized_name)

    # æ¸…ç†ä¸´æ—¶å›¾ç‰‡
    os.remove(content_path)
    os.remove(style_path)
    os.chdir(current_dir)

    return result


def full_pipeline(input_image, input_prompt = None, alpha=0.7, cfg_scale=9, image_strength=0.7):
    # Step 1: ç”Ÿæˆ Prompt
    if input_image is None:
        raise gr.Error("è¯·å…ˆä¸Šä¼ å›¾ç‰‡")

    with tempfile.NamedTemporaryFile(suffix=".png", delete=False) as tmp:
        input_image.save(tmp.name)
        input_path = tmp.name
    
    prompt = generate_prompt(input_image)
    if input_prompt:
        prompt = prompt + ", " + input_prompt
    # Step 2: ç”Ÿæˆé…å¯¹å¤´åƒ
    sampled_img = run_sampler(input_image, prompt, cfg_scale=cfg_scale, image_strength=image_strength)
    # Step 3: é£æ ¼è¿ç§»
    stylized_img = run_adain(sampled_img, input_image, alpha)
    return stylized_img

demo = gr.Interface(
    fn=full_pipeline,
    inputs=[
        gr.Image(type="pil", label="ä¸Šä¼ ä¸€å¼ å¤´åƒ"),
        gr.Textbox(lines=2, placeholder="å¯é€‰ï¼šè¾“å…¥ä½ æƒ³è¦çš„æƒ…ä¾£å¤´åƒç‰¹å¾(In English tags, e.g. girl, facing left, pink dress)", label="è‡ªå®šä¹‰ Prompt"), 
        gr.Slider(minimum=0.0, maximum=1.0, value=0.7, label="é£æ ¼åŒ–ç¨‹åº¦ (alpha)"), 
        gr.Slider(minimum=0, maximum=15, value = 9, label = "æ–‡æœ¬æç¤ºå¼ºåº¦ (CFG Scale)", step=1),
        gr.Slider(minimum=0, maximum=1, value = 0.7, label = "å›¾åƒæç¤ºå¼ºåº¦ (Image Strength)")
    ],
    outputs=[
        gr.Image(type="pil", label="ä½ çš„æƒ…ä¾£å¤´åƒâ¤ï¸")
    ],
    title="ğŸ¨ CUPID: AIæƒ…ä¾£å¤´åƒç”Ÿæˆå™¨",
    description=(
        "âœ¨ ä¸Šä¼ ä¸€å¼ ä½ çš„å¤´åƒï¼ŒCUPID è‡ªåŠ¨å¸®ä½ ç”Ÿæˆä¸“å±çš„æƒ…ä¾£å¤´åƒã€‚\n\n"
        "ğŸ“Œ å¯é€‰è¾“å…¥ä½ æƒ³è¦çš„å¯¹æ–¹å½¢è±¡å…³é”®è¯ï¼ˆå¦‚ï¼šglasses, smilingï¼‰æ¥è°ƒæ•´å†…å®¹ã€‚\n\n"
        "ğŸ¨ é€šè¿‡é£æ ¼è¿ç§»æŠ€æœ¯ï¼Œè®©æ–°å¤´åƒä¸åŸå›¾é£æ ¼åŒ¹é…ã€‚\n\n"
        "ğŸ’• å¿«æ¥è¯•è¯•ï¼Œç”Ÿæˆå±äºä½ ä»¬çš„ä¸“å±æƒ…ä¾£å¤´åƒå§ï¼\n\n"
        "Reminder: æ¨èä¸Šä¼ humanå¤´åƒï¼Œæ•ˆæœæœ€ä½³å“¦ï¼"
    )
)

if __name__ == "__main__":
    load_dotenv()
    os.environ['MKL_THREADING_LAYER'] = 'GNU'

    # è®¾ç½® API å‚æ•°
    openai_api_key = os.getenv("INFINI_API_KEY")
    openai_base_url = os.getenv("INFINI_BASE_URL")
    # æ¨¡å‹ä¸å·¥å…·å¯¼å…¥
    from get_gpt4_prompt import get_prompt
    from sampler import ControlNetSampler, process

    model_config = './models/cldm_v15.yaml'
    model_ckpt = 'checkpoints/last.ckpt'
    sampler = ControlNetSampler(model_config, model_ckpt)
    demo.launch(server_name='0.0.0.0', server_port=7860)